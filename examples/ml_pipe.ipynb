{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating A Pipeline Using MLRUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from mlrun import run_start, mlrun_op\n",
    "from mlrun.iguazio import mount_v3io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Test/Debug the code locally <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m mlrun run -p p1=5 -s file=secrets.txt training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build & Run a KubeFlow Pipeline \n",
    "<b> Define steps (training, validation) <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlrun_train(p1, p2):\n",
    "    return mlrun_op('training', \n",
    "                    command = '/User/kubeflow/training.py', \n",
    "                    params = {'p1':p1, 'p2':p2},\n",
    "                    outputs = {'model.txt':'', 'dataset.csv':''},\n",
    "                    out_path ='v3io:///bigdata/mlrun/{{workflow.uid}}/',\n",
    "                    rundb = '/User')\n",
    "                    \n",
    "# use data from the first step\n",
    "def mlrun_validate(modelfile):\n",
    "    return mlrun_op('validation', \n",
    "                    command = '/User/kubeflow/validation.py', \n",
    "                    inputs = {'model.txt':modelfile},\n",
    "                    out_path ='v3io:///bigdata/mlrun/{{workflow.uid}}/',\n",
    "                    rundb = '/User')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Create a DSL (execution graph/DAG)<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='My MLRUN pipeline',\n",
    "    description='Shows how to use mlrun.'\n",
    ")\n",
    "def mlrun_pipeline(\n",
    "   p1 = 5 , p2 = '\"text\"'\n",
    "):\n",
    "    train = mlrun_train(p1, p2).apply(mount_v3io())\n",
    "    \n",
    "    # feed 1st step results into the secound step\n",
    "    validate = mlrun_validate(train.outputs['model-txt']).apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Create and run experiment <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(mlrun_pipeline, 'mlrunpipe.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/38f4cb06-87e4-4ac0-ac95-00102cadc29c\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/b4e63c25-a3f3-11e9-a4db-000d3a7b7ba7\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client(namespace='default-tenant')\n",
    "arguments = {'p1': 4}\n",
    "experiment = client.create_experiment('mlrun demo')\n",
    "run_result = client.run_pipeline(experiment.id, 'mlrun pipe demo', 'mlrunpipe.yaml', arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Pipeline with Hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First step runs training in parallel (depend on the selected runtime), and generate a list of results \n",
    "* 2nd step selects the best fit result (e.g. best accuracy)\n",
    "* 3rd step runs validation on the selected (best fit) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlrun_train(p1, p2):\n",
    "    return mlrun_op('training', \n",
    "                    command = '/User/kubeflow/training.py', \n",
    "                    params = {'p2':p2},\n",
    "                    hyperparams = {'p1': p1},\n",
    "                    out_path ='v3io:///bigdata/mlrun/{{workflow.uid}}/',\n",
    "                    rundb = '/User')\n",
    "                    \n",
    "# select best fit\n",
    "def mlrun_select(iterations):\n",
    "    return mlrun_op('best_fit', \n",
    "                    command = '/User/kubeflow/best_fit.py', \n",
    "                    params = {'iterations': iterations},\n",
    "                    outputs = {'model.txt':''},\n",
    "                    out_path ='v3io:///bigdata/mlrun/{{workflow.uid}}/',\n",
    "                    rundb = '/User')              \n",
    "\n",
    "# use data from the first step\n",
    "def mlrun_validate(modelfile):\n",
    "    return mlrun_op('validation', \n",
    "                    command = '/User/kubeflow/validation.py', \n",
    "                    inputs = {'model.txt':modelfile},\n",
    "                    out_path ='v3io:///bigdata/mlrun/{{workflow.uid}}/',\n",
    "                    rundb = '/User')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='My MLRUN pipeline',\n",
    "    description='Shows how to use mlrun.'\n",
    ")\n",
    "def mlrun_pipeline(\n",
    "   p1 = [5, 6, 2] , p2 = '\"text\"'\n",
    "):\n",
    "    train = mlrun_train(p1, p2).apply(mount_v3io()).apply(v3io_cred())\n",
    "    \n",
    "    # feed the result list into a \"best fit\" selection step\n",
    "    selector = mlrun_select(train.outputs['iterations']).apply(mount_v3io())\n",
    "    \n",
    "    # feed the best fit model into a validation step\n",
    "    validate = mlrun_validate(selector.outputs['model-txt']).apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(mlrun_pipeline, 'mlrunpipe_hyper.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/032a87b0-94ed-44fd-9a00-4a946264a8e2\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/e0178dcd-a3f3-11e9-a4db-000d3a7b7ba7\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client(namespace='default-tenant')\n",
    "arguments = {'p1': [5, 7, 3]}\n",
    "experiment = client.create_experiment('mlrun demo hyper')\n",
    "run_result = client.run_pipeline(experiment.id, 'mlrun hyper pipe demo', 'mlrunpipe_hyper.yaml', arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
